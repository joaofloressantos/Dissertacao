@article{Sampaio2014,
abstract = {Empowered by virtualisation technology, cloud infrastructures enable the construction of flexible and elastic computing environments, providing an opportunity for energy and resource cost optimisation while enhancing system availability and achieving high performance. A crucial requirement for effective consolidation is the ability to efficiently utilise system resources for high-availability computing and energy-efficiency optimisation to reduce operational costs and carbon footprints in the environment. Additionally, failures in highly networked computing systems can negatively impact system performance substantially, prohibiting the system from achieving its initial objectives. In this paper, we propose algorithms to dynamically construct and readjust virtual clusters to enable the execution of users' jobs. Allied with an energy optimising mechanism to detect and mitigate energy inefficiencies, our decision-making algorithms leverage virtualisation tools to provide proactive fault-tolerance and energy-efficiency to virtual clusters. We conducted simulations by injecting random synthetic jobs and jobs using the latest version of the Google cloud tracelogs. The results indicate that our strategy improves the work per Joule ratio by approximately 12.9{\%} and the working efficiency by almost 15.9{\%} compared with other state-of-the-art algorithms. © 2014 Elsevier B.V. All rights reserved.},
author = {Sampaio, Altino M. and Barbosa, Jorge G.},
doi = {10.1016/j.future.2014.06.008},
file = {:C$\backslash$:/Users/Joao/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sampaio, Barbosa - 2014 - Towards high-available and energy-efficient virtual computing environments in the cloud.pdf:pdf},
isbn = {0167-739X},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Consolidation,Energy-efficiency,Platform elasticity,Proactive fault-tolerance,Scheduling},
pages = {30--43},
publisher = {Elsevier B.V.},
title = {{Towards high-available and energy-efficient virtual computing environments in the cloud}},
url = {http://dx.doi.org/10.1016/j.future.2014.06.008},
volume = {40},
year = {2014}
}
@article{ArabnejadUP,
author = {Arabnejad, Hamid and Barbosa, Jorge G},
file = {:C$\backslash$:/Users/Joao/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Arabnejad, Barbosa - Unknown - Multi-Workflow QoS-Constrained Scheduling for Utility Computing.pdf:pdf},
keywords = {bud-,clouds,concurrent workflows,deadline,grids},
title = {{Multi-Workflow QoS-Constrained Scheduling for Utility Computing}}
}
@article{Ronngren1997,
abstract = {Priority queues are used in many applications including real-time systems, operating systems, and simulations. Their implementation may have a profound effect on the performance of such applications. In this article, we study the performance of well-known sequential priority queue implementations and the recently proposed parallel access priority queues. To accurately assess the performance of a priority queue, the performance measurement methodology must be appropriate. We use the Classic Hold, the Markov Model, and an Up/Down access pattern to measure performance and look at both the average access time and the worst-case time that are of vital interest to real-time applications. Our results suggest that the best choice for priority queue algorithms depends heavily on the application. For queue sizes smaller than 1,000 elements, the Splay Tree, the Skew Heap, and Henriksen’s algorithm show good average access times. For large queue sizes of 5,000 elements or more, the Calendar Queue and the Lazy Queue offer good average access times but have very long worst-case access times. The Skew Heap and the Splay Tree exhibit the best worst-case access times. Among the parallel access priority queues tested, the Parallel Access Skew Heap provides the best performance on small shared memory multiprocessors.},
author = {R{\"{o}}nngren, Robert and Ayani, Rassul},
doi = {10.1145/249204.249205},
issn = {10493301},
journal = {ACM Transactions on Modeling and Computer Simulation},
number = {2},
pages = {157--209},
title = {{A comparative study of parallel and sequential priority queue algorithms}},
volume = {7},
year = {1997}
}
@article{Arabnejad,
author = {Arabnejad, Hamid and Barbosa, Jorge and Arabnejad, Hamid and Barbosa, Jorge},
file = {:D$\backslash$:/Dropbox/Cadeiras/PDIS/Refs/ConcurrentWf.pdf:pdf},
journal = {Fair Resource Sharing for Dynamic Scheduling of Workflows on Heterogeneous Systems, 1st Edition},
keywords = {dynamic scheduling of,fr,hamid arabnejad,jorge barbosa,r resource sharing for,workflows on heterogeneous systems},
pages = {1--22},
title = {{Dynamic Scheduling of Workflows in Heterogeneous Systems}},
volume = {1},
year = {2013}
}
@article{Buyya1999,
abstract = {Page 1. High  Performance Cluster Computing : Architectures and Systems, Volume 1 Edited by Rajkumar Buyya rajkumar@dgs.monash.edu.au School of Computer Science and Software Engineering Monash University Melbourne, Australia Page 2. Contents at a Glance ... $\backslash$n},
author = {Buyya, R},
isbn = {0130137847},
journal = {Prentice Hall PTR},
number = {Journal Article},
pages = {327--350},
title = {{High Performance Cluster Computing: Architectures and Systems, Volume 1}},
volume = {82},
year = {1999}
}
@inproceedings{Zhao2006,
abstract = {The problem of scheduling a single DAG onto heterogeneous systems has been studied extensively. In this paper, we focus on the problem of scheduling more than one DAG at the same time onto a set of heterogeneous resources. The aim is not only to optimize the overall makespan, but also to achieve fairness, defined on the basis of the slowdown that each DAG would experience as a result of competing for resources with other DAGs. Two policies particularly focussing to deliver fairness are presented and evaluated along with another four policies that can be used to schedule multiple DAGs.},
author = {Zhao, Henan and Sakellariou, Rizos},
booktitle = {20th International Parallel and Distributed Processing Symposium, IPDPS 2006},
doi = {10.1109/IPDPS.2006.1639387},
isbn = {1424400546},
title = {{Scheduling multiple DAGs onto heterogeneous systems}},
volume = {2006},
year = {2006}
}
@inproceedings{Xu2009,
abstract = {Cloud computing has gained popularity in recent times. As a cloud must provide services to many users at the same time and different users have different QoS requirements, the scheduling strategy should be developed for multiple workflows with different QoS requirements. In this paper, we introduce a multiple QoS constrained scheduling strategy of multi-workflows (MQMW) to address this problem. The strategy can schedule multiple workflows which are started at any time and the QoS requirements are taken into account. Experimentation shows that our strategy is able to increase the scheduling success rate significantly.},
author = {Xu, Meng and Cui, Lizhen and Wang, Haiyang and Bi, Yanbing},
booktitle = {Proceedings - 2009 IEEE International Symposium on Parallel and Distributed Processing with Applications, ISPA 2009},
doi = {10.1109/ISPA.2009.95},
isbn = {9780769537474},
keywords = {Cloud computing,Multiple QoS requirements,Multiple workflows,Scheduling},
pages = {629--634},
title = {{A multiple QoS constrained scheduling strategy of multiple workflows for cloud computing}},
year = {2009}
}
@article{Arabnejad2012,
abstract = {For most Heterogeneous Computing Systems (HCS) the completion time of an application is the most important requirement. Many applications are represented by a workflow that is therefore schedule in a HCS system. Recently, researchers have proposed algorithms for concurrent workflow scheduling in order to improve the execution time of several applications in a HCS system. Although, most of these algorithms were designed for static scheduling, that is all application must be submitted at the same time, there are a few algorithms, such as OWM (online workflow Management) and RANK{\_}HYBD, that were presented for dealing with dynamic application scheduling. In this paper, we present a new algorithm for dynamic application scheduling. The algorithm focus on the Quality of Service (QoS) experienced by each application (or user). It reduces the waiting and execution times of each individual workflow, unlike other algorithms that give privilege to average completion time of all workflows. The simulation results show that the proposed approach significantly outperforms the other algorithms in terms of individual response time.},
author = {Arabnejad, Hamid and Barbosa, Jorge},
doi = {10.1109/ISPA.2012.94},
isbn = {978-1-4673-1631-6},
journal = {2012 IEEE 10th International Symposium on Parallel and Distributed Processing with Applications},
pages = {633--639},
title = {{Fairness Resource Sharing for Dynamic Workflow Scheduling on Heterogeneous Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6280354},
year = {2012}
}
@article{Topcuoglu2002,
abstract = {Efficient application scheduling is critical for achieving high performance in heterogeneous computing environments. The application scheduling problem has been shown to be NP-complete in general cases as well as in several restricted cases. Because of its key importance, this problem has been extensively studied and various algorithms have been proposed in the literature which are mainly for systems with homogeneous processors. Although there are a few algorithms in the literature for heterogeneous processors, they usually require significantly high scheduling costs and they may not deliver good quality schedules with lower costs. In this paper, we present two novel scheduling algorithms for a bounded number of heterogeneous processors with an objective to simultaneously meet high performance and fast scheduling time, which are called the Heterogeneous Earliest-Finish-Time (HEFT) algorithm and the Critical-Path-on-a-Processor (CPOP) algorithm. The HEFT algorithm selects the task with the highest upward rank value at each step and assigns the selected task to the processor, which minimizes its earliest finish time with an insertion-based approach. On the other hand, the CPOP algorithm uses the summation of upward and downward rank values for prioritizing tasks. Another difference is in the processor selection phase, which schedules the critical tasks onto the processor that minimizes the total execution time of the critical tasks. In order to provide a robust and unbiased comparison with the related work, a parametric graph generator was designed to generate weighted directed acyclic graphs with various characteristics. The comparison study, based on both randomly generated graphs and the graphs of some real applications, shows that our scheduling algorithms significantly surpass previous approaches in terms of both quality and cost of schedules, which are mainly presented with schedule length ratio, speedup, frequency of best results, and average scheduling time metrics},
author = {Topcuoglu, Haluk and Hariri, Salim and Wu, M},
doi = {10.1109/71.993206},
isbn = {0769524486},
issn = {10459219},
journal = {Parallel and Distributed Systems, {\ldots}},
keywords = {DAG scheduling,heterogeneous systems,list scheduling,mapping,task graphs},
number = {3},
pages = {260--274},
title = {{Performance-effective and low-complexity task scheduling for heterogeneous computing}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=993206},
volume = {13},
year = {2002}
}
@inproceedings{Sakellariou2004,
abstract = {Summary form only given. This paper is motivated by the observation that different methods to compute the weights of nodes and edges when scheduling DAGs onto heterogeneous machines may lead to significant variations in the generated schedule. To minimize such variations, we present a novel heuristic for DAG scheduling, which is based upon solving a series of independent task scheduling problems. A novel heuristic for the latter problem is also included. Both heuristics compare favourably with other related heuristics.},
author = {Sakellariou, R and Zhao, Henan},
booktitle = {Parallel and Distributed Processing Symposium, 2004. Proceedings. 18th International},
doi = {10.1109/IPDPS.2004.1303065},
isbn = {0-7695-2132-0},
keywords = {Computer science,Costs,DAG scheduling,Distributed processing,Processor scheduling,directed graph,directed graphs,heterogeneous system,hybrid heuristic,minimization,scheduling,task scheduling},
pages = {111--123},
title = {{A hybrid heuristic for DAG scheduling on heterogeneous systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1303065},
year = {2004}
}
@inproceedings{NTakpe2009,
abstract = {Scheduling multiple applications on heterogeneous multi-clusters is challenging as the different applications have to compete for resources. A scheduler thus has to ensure a fair distribution of resources among the applications and prevent harmful selfish behaviors while still trying to minimize their respective completion time. In this paper we consider mixed-parallel applications, represented by graphs whose nodes are data-parallel tasks, that are scheduled in two steps: allocation and mapping. We investigate several strategies to constrain the amount of resources the scheduler can allocate to each application and evaluate them over a wide range of scenarios.},
author = {N'Takp{\'{e}}, Tchimou and Suter, Fr{\'{e}}d{\'{e}}ric},
booktitle = {IPDPS 2009 - Proceedings of the 2009 IEEE International Parallel and Distributed Processing Symposium},
doi = {10.1109/IPDPS.2009.5161161},
isbn = {9781424437504},
issn = {1530-2075},
title = {{Concurrent scheduling of parallel task graphs on multi-clusters using constrained resource allocations}},
year = {2009}
}
@article{Hirales-Carbajal2012,
abstract = {In this paper, we present an experimental study of deterministic non-preemptive multiple workflow scheduling strategies on a Grid. We distinguish twenty five strategies depending on the type and amount of information they require. We analyze scheduling strategies that consist of two and four stages: labeling, adaptive allocation, prioritization, and parallel machine scheduling. We apply these strategies in the context of executing the Cybershake, Epigenomics, Genome, Inspiral, LIGO, Montage, and SIPHT workflows applications. In order to provide performance comparison, we performed a joint analysis considering three metrics. A case study is given and corresponding results indicate that well known DAG scheduling algorithms designed for single DAG and single machine settings are not well suited for Grid scheduling scenarios, where user run time estimates are available. We show that the proposed new strategies outperform other strategies in terms of approximation factor, mean critical path waiting time, and critical path slowdown. The robustness of these strategies is also discussed.},
author = {Hirales-Carbajal, Ad??n and Tchernykh, Andrei and Yahyapour, Ramin and Gonz??lez-Garc??a, Jos?? Luis and R??blitz, Thomas and Ram??rez-Alcaraz, Juan Manuel},
doi = {10.1007/s10723-012-9215-6},
issn = {15707873},
journal = {Journal of Grid Computing},
keywords = {Grid computing,Resource management,User run time estimate,Workflow scheduling},
number = {2},
pages = {325--346},
title = {{Multiple workflow scheduling strategies with user run time estimates on a Grid}},
volume = {10},
year = {2012}
}
@article{Kwok1999,
abstract = {Static scheduling of a program represented by a directed task graph on a multiprocessor system to minimize the program completion time is a well-known problem in parallel processing. Since finding an optimal schedule is an NP- complete problem in general, researchers have resorted to devising efficient heuristics. A plethora of heuristics have been proposed based on a wide spectrum of techniques, including branch-and-bound, integer-programming, searching, graph- theory, randomization, genetic algorithms, and evolutionary methods. The objective of this survey is to describe various scheduling algorithms and their functionalities in a contrasting fashion as well as examine their relative merits in terms of performance and time-complexity. Since these algorithms are based on diverse assumptions, they differ in their functionalities, and hence are difficult to describe in a unified context. We propose a taxonomy that classifies these algorithms into different categories. We consider 27 scheduling algorithms, with each algorithm explained through an easy-to-understand description followed by an illustrative example to demonstrate its operation. We also outline some of the novel and promising optimization approaches and current research trends in the area. Finally, we give an overview of the software tools that provide scheduling/mapping functionalities.},
author = {Kwok, Yu-Kwong and Ahmad, Ishfaq},
doi = {10.1145/344588.344618},
isbn = {0360-0300},
issn = {03600300},
journal = {ACM Computing Surveys},
number = {4},
pages = {406--471},
title = {{Static scheduling algorithms for allocating directed task graphs to multiprocessors}},
volume = {31},
year = {1999}
}
@article{Liu2009,
abstract = {Transaction-intensive grid workflows are attracting more and more attentions with the prosperity of e-business and e-government applications. They are workflows normally with a huge number of relatively simple concurrent instances, such as business transactions, whilst some of which may involve considerable communication overheads. However, there are almost no specific scheduling algorithms which deal with such workflows, and existing scheduling algorithms are not efficient enough for such a scenario if corresponding adjustments are not conducted. To address this problem, we propose a novel Min-Min-Average (MMA) algorithm for efficiently scheduling transaction-intensive grid workflows involving considerable communication overheads. The MMA algorithm is based on the popular Min-Min algorithm but uses a different strategy for transaction-intensive grid workflows with the capability of adapting to the change of network transmission speed automatically. The comparison based on the simulation performed on SwinDeW-G, our peer-to-peer based grid workflow environment, demonstrates that the MMA algorithm can improve the scheduling performance significantly over the original Min-Min algorithm when scheduling transaction-intensive grid workflows with considerable communication overheads involved.},
author = {Liu, Ke and Chen, Jinjun and Jin, Hai and Yang, Yun},
isbn = {9781920682804},
issn = {14451336},
journal = {Conferences in Research and Practice in Information Technology Series},
keywords = {Grid workflows,Scheduling algorithms,Transaction-intensive workflows},
pages = {41--48},
title = {{A Min-Min average algorithm for scheduling Transaction-intensive grid workflows}},
volume = {99},
year = {2009}
}
@article{Maheswaran1999,
abstract = {Dynamic mapping (matching and scheduling) heuristics for a class of independent tasks using heterogeneous distributed computing systems are studied. Two types of mapping heuristics are considered: on-line and batch mode heuristics. Three new heuristics, one for batch and two for on-line, are introduced as part of this research. Simulation studies are performed to compare these heuristics with some existing ones. In total, five on-line heuristics and three batch heuristics are examined. The on-line heuristics consider; to varying degrees and in different ways, task affinity for different machines and machine ready times. The batch heuristics consider these factors, as well as aging of tasks waiting to execute. The simulation results reveal that the choice of mapping heuristic depends on parameters such as: (a) the structure of the heterogeneity among tasks and machines, (b) the optimization requirements, and (c) the arrival rate of the tasks},
author = {Maheswaran, M. and Ali, S. and Siegal, H.J. and Hensgen, D. and Freund, R.F.},
doi = {10.1109/HCW.1999.765094},
isbn = {0-7695-0107-9},
issn = {1097-5209},
journal = {Proceedings. Eighth Heterogeneous Computing Workshop (HCW'99)},
pages = {107--131},
title = {{Dynamic matching and scheduling of a class of independent tasks onto heterogeneous computing systems}},
volume = {131},
year = {1999}
}
@article{Casanova2008,
abstract = {We presented the SimGrid simulation framework whose goal is to provide a generic evaluation tool for large-scale distributed computing. Its main components are: two APIs for researchers who study algorithm and need to prototype simulations quickly, and two for developers who can develop applications in the comfort of the simulated world before deploying them seamlessly in the real world. SimGrid employs a modular simulation kernel that supports the addition and use of new resource models without changes in the user code. We used this feature ourselves to implement several simulation models and even to integrate the GTNetS packet-level simulator.},
author = {Casanova, Henri and Legrand, Arnaud and Quinson, Martin},
doi = {10.1109/UKSIM.2008.28},
isbn = {978-0-7695-3114-4},
journal = {Tenth International Conference on Computer Modeling and Simulation (uksim 2008)},
pages = {126--131},
title = {{SimGrid: A Generic Framework for Large-Scale Distributed Experiments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4488918},
year = {2008}
}
@article{Velho2009,
abstract = {Distributed computing is a very broad and active research area comprising fields such as cluster computing, computational grids, desktop grids and peer-to-peer (P2P) systems. Studies in this area generally resort to simulations, which enable reproducible results and make it possible to explore wide ranges of platform and application scenarios. In this context, network simulation is certainly the most critical part. Many packet-level network simulators are available and enable high-accuracy simulation but they lead to prohibitively long simulation times. Therefore, many simulation frameworks have been developed that simulate networks at higher levels, thus enabling fast simulation but losing accuracy. One such framework, SimGrid, uses a flow-level approach that approximates the behavior of TCP networks, including TCP's bandwidth sharing properties. A preliminary study of the accuracy loss by comparing it to popular packet-level simulators has been proposed in [11] and in which regimes in which SimGrid's accuracy is comparable to that of these packet-level simulators are identified. In this article we come back on this study, reproduce these experiments and provide a deeper analysis that enables us to greatly improve SimGrid's range of validity.},
author = {Velho, Pedro and Legrand, Arnaud},
doi = {10.4108/ICST.SIMUTOOLS2009.5592},
isbn = {978-963-9799-45-5},
journal = {Proceedings of the 2nd International Conference on Simulation Tools and Techniques},
keywords = {*zotero-import-10-12-02},
pages = {1--10},
title = {{Accuracy study and improvement of network simulation in the {\{}SimGrid{\}} framework}},
url = {http://eudl.eu/doi/10.4108/ICST.SIMUTOOLS2009.5592},
year = {2009}
}
@article{Bittencourt2010,
abstract = {The workflow paradigm has become the standard to represent processes and their execution flows. With the evolution of e-Science, workflows are becoming larger and more computational demanding. Such e-Science necessities match with what computational Grids have to offer. Grids are shared distributed platforms which will eventually receive multiple requisitions to execute workflows. With this, there is a demand for a scheduler which deals with multiple workflows in the same set of resources, thus the development of multiple workflow scheduling algorithms is necessary. In this paper we describe four different initial strategies for scheduling multiple workflows on Grids and evaluate them in terms of schedule length and fairness. We present results for the initial schedule and for the makespan after the execution with external load. From the results we conclude that interleaving the workflows on the Grid leads to good average makespan and provides fairness when multiple workflows share the same set of resources.},
author = {Bittencourt, Luiz Fernando and Madeira, Edmundo R M},
doi = {10.1007/s10723-009-9144-1},
issn = {15707873},
journal = {Journal of Grid Computing},
keywords = {Grid computing,Scheduling,Workflow},
number = {3},
pages = {419--441},
title = {{Towards the scheduling of multiple workflows on computational Grids}},
volume = {8},
year = {2010}
}
@article{Casanova2010,
abstract = {Many scientific applications can be structured as parallel task graphs (PTGs), that is, graphs of data-parallel tasks. Adding data parallelism to a task-parallel application provides opportunities for higher performance and scalability, but poses additional scheduling challenges. In this paper, we study the off-line scheduling of multiple PTGs on a single, homogeneous cluster. The objective is to optimize performance without compromising fairness among the PTGs. We consider the range of previously proposed scheduling algorithms applicable to this problem, from both the applied and the theoretical literature, and we propose minor improvements when possible. Our main contribution is an extensive evaluation of these algorithms in simulation, using both synthetic and real-world application configurations, using two different metrics for performance and one metric for fairness. We identify a handful of algorithms that provide good trade-offs when considering all these metrics. The best algorithm overall is one that structures the schedule as a sequence of phases of increasing duration based on a makespan guarantee produced by an approximation algorithm. ?? 2010 Elsevier Inc. All rights reserved.},
author = {Casanova, Henri and Desprez, Frdric and Suter, Frdric},
doi = {10.1016/j.jpdc.2010.08.017},
isbn = {0743-7315},
issn = {07437315},
journal = {Journal of Parallel and Distributed Computing},
keywords = {Cluster,Multi-criteria scheduling,Parallel task graphs,Resource allocation},
number = {12},
pages = {1193--1203},
title = {{On cluster resource allocation for multiple parallel task graphs}},
volume = {70},
year = {2010}
}
@inproceedings{Barbosa2011,
abstract = {This paper addresses the problem of minimizing the scheduling length (make-span) of a batch of jobs with different arrival times. A job is described by a direct acyclic graph (DAG) of parallel tasks. The paper proposes a dynamic scheduling method that adapts the schedule when new jobs are submitted and that may change the processors assigned to a job during its execution. The scheduling method is divided into a scheduling strategy and a scheduling algorithm. We also propose an adaptation of the Heterogeneous Earliest-Finish-Time (HEFT) algorithm, called here P-HEFT, to handle parallel tasks in heterogeneous clusters with good efficiency without compromising the makespan. The results of a comparison of this algorithm with another DAG scheduler using a simulation of several machine configurations and job types shows that P-HEFT gives a shorter makespan for a single DAG but scores worse for multiple DAGs. Finally, the results of the dynamic scheduling of a batch of jobs using the proposed scheduler method showed significant improvements for more heavily loaded machines when compared to the alternative resource reservation approach. ?? 2010 Elsevier B.V. All rights reserved.},
author = {Barbosa, Jorge G. and Moreira, Belmiro},
booktitle = {Parallel Computing},
doi = {10.1016/j.parco.2010.12.004},
issn = {01678191},
keywords = {Image data,List scheduling,Multiple DAG,Non-deterministic job arrival,Parallel task scheduling},
pages = {428--438},
title = {{Dynamic scheduling of a batch of parallel task jobs on heterogeneous clusters}},
volume = {37},
year = {2011}
}
@inproceedings{Yu2008,
abstract = {Workflow applications are gaining popularity in recent years because of the prevalence of cluster environments. Many algorithms have been developed since, however most static algorithms are designed in the problem domain of scheduling single workflow applications, thus not applicable to a common cluster environment where multiple workflow applications and other independent jobs compete for resources. Dynamic scheduling approaches can handle the mixed workload practically by nature but their performance has yet to optimize as they do not have a global view of workflow applications. Recent research efforts suggest merging multiple workflows into one workflow before execution, but fail to address an important issue that multiple workflow applications may be submitted at different times by different users. In this paper, we propose a planner-guided dynamic scheduling strategy for multiple workflow applications, leveraging job dependence information and execution time estimation.Our approach schedules individual jobs dynamically without requiring merging the workflow applications a priori. The simulation results show that the proposed algorithm significantly outperforms two other algorithms by 43.6{\%} and 36.7{\%} with respect to workflow makespan and turnaround time respectively, and it performs even better when the number of concurrent workflow applications increases and the resources are scarce.},
author = {Yu, Zhifeng and Shi, Weisong},
booktitle = {Proceedings of the International Conference on Parallel Processing Workshops},
doi = {10.1109/ICPP-W.2008.10},
isbn = {9780769533759},
issn = {15302016},
pages = {1--8},
title = {{A planner-guided scheduling strategy for multiple workflow applications}},
year = {2008}
}
@article{Hsu2011,
abstract = {Scheduling workflow applications in grid environments is a great challenge, because it is an NP-complete problem. Many heuristic methods have been presented in the literature and most of them deal with a single workflow application at a time. In recent years, several heuristic methods have been proposed to deal with concurrent workflows or online workflows, but they do not work with workflows composed of data-parallel tasks. In this paper, we present an online scheduling approach for multiple mixed-parallel workflows in grid environments. The proposed approach was evaluated with a series of simulation experiments and the results show that the proposed approach delivers good performance and outperforms other methods under various workloads.},
author = {Hsu, Chih-Chiang and Huang, Kuo-Chan and Wang, Feng-Jian},
doi = {10.1016/j.future.2010.10.015},
isbn = {0167-739X},
issn = {0167739X},
journal = {Future Generation Computer Systems},
number = {6},
pages = {860--870},
title = {{Online scheduling of workflow applications in grid environments}},
url = {http://dx.doi.org/10.1016/j.future.2010.10.015},
volume = {27},
year = {2011}
}
@article{Arabnejad2014,
abstract = {Service-oriented computing has enabled a new method of service provisioning based on utility computing models, in which users consume services based on their Quality of Service (QoS) requirements. In such pay-per-use models, users are charged for services based on their usage and on the fulfilment of QoS constraints; execution time and cost are two common QoS requirements. Therefore, to produce effective scheduling maps, service pricing must be considered while optimising execution performance. In this paper, we propose a Heterogeneous Budget Constrained Scheduling (HBCS) algorithm that guarantees an execution cost within the user{\&}rsquo;s specified budget and that minimises the execution time of the user{\&}rsquo;s application. The results presented show that our algorithm achieves lower makespans, with a guaranteed cost per application and with a lower time complexity than other budget-constrained state-of-the-art algorithms. The improvements are particularly high for more heterogeneous systems, in which a reduction of 30 {\%} in execution time was achieved while maintaining the same budget level.},
author = {Arabnejad, Hamid and Barbosa, Jorge G.},
doi = {10.1007/s10723-014-9294-7},
isbn = {978-3-319-09153-2},
issn = {15707873},
journal = {Journal of Grid Computing},
keywords = {Deadline,Planning Success Rate,Quality of Service,Utility computing},
number = {4},
pages = {665--679},
title = {{A Budget Constrained Scheduling Algorithm for Workflow Applications}},
volume = {12},
year = {2014}
}
@incollection{Arabnejad2014a,
abstract = {Scheduling independent workflows on shared resources in a way that satisfy users Quality of Service is a significant challenge. In this study, we describe methodologies for off-line scheduling, where a schedule is generated for a set of knownworkflows, and on-line scheduling, where users can submit workflows at any moment in time. We consider the on-line scheduling problem in more detail and present performance comparisons of state-of-the-art algorithms for a realistic model of a heterogeneous system.},
author = {Arabnejad, Hamid and Barbosa, Jorge G. and Suter, Fr??d??ric},
booktitle = {High-Performance Computing on Complex Environments},
doi = {10.1002/9781118711897.ch9},
isbn = {9781118711897},
keywords = {Fairness dynamic workflow scheduling (FDWS),Heterogeneous computing systems (HCSs),Offline concurrent workflow scheduling,Online concurrent workflow scheduling,Online max-min,Online min-min,Online workflow management (OWM),Rank hybrid (Rank{\_}Hybd)},
pages = {145--167},
title = {{Fair Resource Sharing for Dynamic Scheduling of Workflows on Heterogeneous Systems}},
year = {2014}
}
@incollection{Karger2010,
abstract = {In this survey we focus exclusively on algorithms that provably run, in the worst case, in time polynomial in the size of the input. If the algorithm always gives an optimum solution, we call it an exact algorithm. Many of the problems that we consider, however, are NP-hard, and it thus seems unlikely that polynomial-time algorithms exist to solve them. In these cases we will be interested in approximation algorithms; we deﬁne a $\rho$-approximation algorithm to be an algorithm that runs in polynomial time and delivers a solution of value at most $\rho$ times the optimum.},
author = {Karger, David and Stein, Cliff and Wein, Joel},
booktitle = {Algorithms and Theory of Computation Handbook (2nd edition)},
isbn = {978-1-58488-820-8},
keywords = {Instruction Scheduling},
pages = {20:1--20:34},
title = {{Scheduling Algorithms}},
url = {http://dl.acm.org/citation.cfm?id=1882723.1882743},
volume = {2},
year = {2010}
}
